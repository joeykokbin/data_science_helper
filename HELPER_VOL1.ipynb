{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions Volume 1: (FILE IO)\n",
    "\n",
    "Author: Koh Kok Bin  \n",
    "Date: 27th Oct 2021\n",
    "\n",
    "This notebook provides some helper functions that users can use in their Python code to interact with files. This is relating to a broader topic known as File I/O (Input/Output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant packages. No need additional installation of packages.\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get directory name of this file. Helpful to specify the directory of the file, \n",
    "# so you can also interact with the files in the same location via relative paths.\n",
    "dirname = globals()[\"_dh\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note that you can also read sharepoint files like so:__  \n",
    "The r in front of the quotation mark specifies Python to treat it like a raw string. Else, the forward slash \"\\\\\" is treated as an escape character as it is used in conjunction with other characters such as \\t for tab, \\n for newline in print statements.  \n",
    "\n",
    "Try out the 2 cells below. Error comes because the slash is a *special character*. To tell Python not to interpret it as a special character, we need to add another forward slash to it to *escape* it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-7-dff1232de400>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-dff1232de400>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    print(\"\\\")\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "print(\"\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\n"
     ]
    }
   ],
   "source": [
    "print(\"\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"W:\" link only works if you've connected the path (W drive) via windows explorer. You must also have read access to the following directory. Try your own sharepoint link!  \n",
    "\n",
    "*Note: Does not work well with DOS-domain accounts. This is because you are running this script as a SOE account user (aka what you used to log into this laptop/workstation). If you've logged into SharePoint via dos-account, it will cause errors.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydir = r\"W:\\NAC\\Workgroup\\PST\\Reference Materials\\Usable Codes\\Python\\File IO\\main\"\n",
    "shareptdir = r\"\\\\intranet.dos.gov.sg\\DavWWWRoot\\sites\\ead2\\Common\\NAC\\Workgroup\\PST\\Reference Materials\\Usable Codes\\Python\\File IO\\main\"\n",
    "print(os.listdir(mydir))\n",
    "print(os.listdir(shareptdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try this (remove the comments) to see the error it will through without specifying it as a raw string.\n",
    "#shareptdir = \"\\\\intranet.dos.gov.sg\\DavWWWRoot\\sites\\ead2\\Common\\NAC\\Workgroup\\PST\\Reference Materials\\Documentation_Guides\"\n",
    "#print(os.listdir(shareptdir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id = \"VOL1_toc\"> Part 1: File I/O (Input/Output)  </a>\n",
    "\n",
    "This section deals with file interaction, including reading and writing to files. Particularly, this will also include reading of and writing to excel files (encrypted or not) as that is the default file format DOS uses to store data.  \n",
    "\n",
    "The pandas package is one of the most commonly used (and most popoular) data processing/manipulation framework in Python. It has many functions that make it easy for users like you or me to manipulate external data sources, especially from Excel. Despite that, it's not a silver bullet. We __need to take note how the data looks like within the files__ in order to interact with them.  \n",
    "\n",
    "The following sections below will describe both pandas and native Python functions for this purpose.  \n",
    "\n",
    "File formats\n",
    "- [csv (Comma Separated Values)](#VOL1_csv)\n",
    "- [xlsx, xls, xlsm (excel files)](#VOL1_excel)\n",
    "- [dat, txt](#VOL1_dat)\n",
    "- [sas7bdat](#VOL1_sas)\n",
    "- [json](#VOL1_json) \n",
    "\n",
    "Part 2: Writing to files\n",
    "- [Excel Files](#VOL1_write_excel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id = \"VOL1_csv\">Part 1a: CSV files</a>\n",
    "\n",
    "[Return to Table of Contents](#VOL1_toc)\n",
    "\n",
    "CSV files are simply text files with each value separated by a comma. In the context of 2-dimensional tables, each line (row) is separated by a newline (intepreted by Python as a \\n). Highly recommended to use Pandas to read in a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace, a string method, is used because os.path.join will use appropriate slashes, but may be the opposite slash.\n",
    "# This makes it consistent throughout the path.\n",
    "path_to_file = os.path.join(dirname, \"files\", \"read\").replace(\"\\\\\", \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV files only have 1 'sheet' if you save from excel files.\n",
    "# If you read the csv files in excel, they will show a structure similar to excel files (1 value in each cell)\n",
    "# However, they are separated by commas. You will run into errors trying to read csv via read_excel.\n",
    "csv_file = os.path.join(path_to_file, \"data.csv\").replace(\"\\\\\", \"/\")\n",
    "df_csv = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My personal preference for all columns to be uppercase so I can reference them consistently via uppercase.\n",
    "df_csv.columns = map(str.upper, df_csv.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error\n",
    "# pd.read_excel(csv_file, sheet_name = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>27</td>\n",
       "      <td>56.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy</td>\n",
       "      <td>30</td>\n",
       "      <td>45.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alfred</td>\n",
       "      <td>24</td>\n",
       "      <td>63.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benjamin</td>\n",
       "      <td>35</td>\n",
       "      <td>85.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       NAME  AGE  SCORE\n",
       "0      John   27   56.9\n",
       "1       Amy   30   45.7\n",
       "2    Alfred   24   63.4\n",
       "3  Benjamin   35   85.3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding = None. File contents = ['ï»¿Name,Age,Score\\n', 'John,27,56.9\\n', 'Amy,30,45.7\\n', 'Alfred,24,63.4\\n', 'Benjamin,35,85.3\\n']\n",
      "Encoding = UTF-8. File contents = ['\\ufeffName,Age,Score\\n', 'John,27,56.9\\n', 'Amy,30,45.7\\n', 'Alfred,24,63.4\\n', 'Benjamin,35,85.3\\n']\n",
      "Encoding = UTF-8-sig. File contents = ['Name,Age,Score\\n', 'John,27,56.9\\n', 'Amy,30,45.7\\n', 'Alfred,24,63.4\\n', 'Benjamin,35,85.3\\n']\n"
     ]
    }
   ],
   "source": [
    "# If you would like to walk on glass...\n",
    "# Why I recommend using Python...\n",
    "encode = [None, \"UTF-8\", \"UTF-8-sig\"]\n",
    "\n",
    "for i in range(3):\n",
    "    with open(csv_file, \"r\", encoding = encode[i]) as file:\n",
    "        print(\"Encoding = {}. File contents = {}\".format(encode[i], file.readlines()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to the pd.read_csv as above. seems much easier no? No need to specify the type of encoding AND the input is read in as a DataFrame already."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id = \"VOL1_excel\">Part 1B: Excel files</a>\n",
    "\n",
    "[Return to Table of Contents](#VOL1_toc)\n",
    "\n",
    "In this section, we will cover how to read from excel files, encrypted or not, in the different file formats that you encounter them in. Generally, there is no information loss when saving your .xls file as .xlsx. Please try your best to save excel files using the latter file formats. Doing large scale processing via Python with such files will reduce the potential for error vs .xls files which the packages may not be fully compatible with.\n",
    "\n",
    "In any case, the file formats (.xlsx, .xlsm, .xls) are all accepted by the pandas function: read_excel(). Do note that anytime you specify arguments (see below) such as *sheet_name = \"Sheet1\"*, the \"Sheet1\" must be case sensitive. In fact, most arguments accepted by Python function are usually case sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For excel files: works with xls, and xlsm too. <check for FAME files>\n",
    "excel_file = os.path.join(path_to_file, \"data.xlsx\").replace(\"\\\\\", \"/\")\n",
    "df_excel = pd.read_excel(excel_file, sheet_name = \"Sheet1\")\n",
    "df_excel.columns = map(str.upper, df_excel.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>27</td>\n",
       "      <td>56.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy</td>\n",
       "      <td>30</td>\n",
       "      <td>45.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alfred</td>\n",
       "      <td>24</td>\n",
       "      <td>63.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benjamin</td>\n",
       "      <td>35</td>\n",
       "      <td>85.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       NAME  AGE  SCORE\n",
       "0      John   27   56.9\n",
       "1       Amy   30   45.7\n",
       "2    Alfred   24   63.4\n",
       "3  Benjamin   35   85.3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file2 = os.path.join(path_to_file, \"data.xls\").replace(\"\\\\\", \"/\")\n",
    "df_xls = pd.read_excel(excel_file2, sheet_name = \"Sheet1\")\n",
    "df_xls.columns = map(str.upper, df_xls.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>27</td>\n",
       "      <td>56.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy</td>\n",
       "      <td>30</td>\n",
       "      <td>45.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alfred</td>\n",
       "      <td>24</td>\n",
       "      <td>63.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benjamin</td>\n",
       "      <td>35</td>\n",
       "      <td>85.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       NAME  AGE  SCORE\n",
       "0      John   27   56.9\n",
       "1       Amy   30   45.7\n",
       "2    Alfred   24   63.4\n",
       "3  Benjamin   35   85.3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file3 = os.path.join(path_to_file, \"data.xlsm\").replace(\"\\\\\", \"/\")\n",
    "df_xlsm = pd.read_excel(excel_file3, sheet_name = \"Sheet1\")\n",
    "df_xlsm.columns = map(str.upper, df_xlsm.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>27</td>\n",
       "      <td>56.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy</td>\n",
       "      <td>30</td>\n",
       "      <td>45.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alfred</td>\n",
       "      <td>24</td>\n",
       "      <td>63.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benjamin</td>\n",
       "      <td>35</td>\n",
       "      <td>85.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       NAME  AGE  SCORE\n",
       "0      John   27   56.9\n",
       "1       Amy   30   45.7\n",
       "2    Alfred   24   63.4\n",
       "3  Benjamin   35   85.3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xlsm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For read_excel, the powerful part is that you can read in the specified sheet (\"Sheet1\") or all sheets (None)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>27</td>\n",
       "      <td>56.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy</td>\n",
       "      <td>30</td>\n",
       "      <td>45.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alfred</td>\n",
       "      <td>24</td>\n",
       "      <td>63.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benjamin</td>\n",
       "      <td>35</td>\n",
       "      <td>85.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  Age  Score\n",
       "0      John   27   56.9\n",
       "1       Amy   30   45.7\n",
       "2    Alfred   24   63.4\n",
       "3  Benjamin   35   85.3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read multiple sheets. Useful if you want to read multiple sheets at a time.\n",
    "dict_excel = pd.read_excel(excel_file, sheet_name = None)\n",
    "dict_excel[\"Sheet1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, I have shown that the same function to read in different file formats will yield the same data. Let's move on to password-protected files. We use a package called xlwings to do that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1Bi: Reading password-protected excel files  \n",
    "[Return to Table of Contents](#VOL1_toc)  \n",
    "\n",
    "I have already created a simple function to help me read encrypted excel files. You can find this solution if you google \"python read encrypted excel file xlwings\". xlwings is the package that we need to use to interact with encrypted files (also workable on unencrypted files too). Importing functions into Jupyter Notebooks can be done by specifying the .py file containing the function in the same directory (or subdirectory).  \n",
    "\n",
    "You can also define (e.g. create) the function in this Notebook, but you cannot import it elsewhere (importing of packages/functions require .py file formats). Please feel free to change the function to suit your work needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_pswd_excel in module helper:\n",
      "\n",
      "read_pswd_excel(link, sheet, excel_range='', return_df=True)\n",
      "    Simple helper function to read password-protected Excel files\n",
      "    \n",
      "    link:           Link of excel file to read.\n",
      "    sheet:          Sheet of Excel File. (will throw error if sheet is not found)\n",
      "    excel_range:    string of an excel range such as \"A1:G20\"\n",
      "    return_df:      To return as list of list (False) or a dataframe (True).\n",
      "    \n",
      "    Each element in the list of list is a row. \n",
      "    Each element in a row would be a column, starting from excel_range\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If importing functions from elsewhere.\n",
    "# helper.py must be in the same directory as this notebook.\n",
    "from helper import read_pswd_excel\n",
    "\n",
    "# To check if function exists in current environment\n",
    "help(read_pswd_excel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To facilitate understanding, I will also copy the function down here so you can easily refer to the code. This code also works on SharePoint files too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires xlwings, as well as os and pandas\n",
    "import os\n",
    "import pandas\n",
    "import xlwings as xw\n",
    "\n",
    "def read_pswd_excel(link, sheet, excel_range = \"\", return_df = True):\n",
    "    \n",
    "    ''' \n",
    "    Simple helper function to read password-protected Excel files\n",
    "    \n",
    "    link:           Link of excel file to read.\n",
    "    sheet:          Sheet of Excel File. (will throw error if sheet is not found)\n",
    "    excel_range:    string of an excel range such as \"A1:G20\"\n",
    "    return_df:      To return as list of list (False) or a dataframe (True).\n",
    "    \n",
    "    Each element in the list of list is a row. \n",
    "    Each element in a row would be a column, starting from excel_range\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if not os.path.exists(link):\n",
    "        print(\"link does not exist. Please try again.\")\n",
    "        raise Exception(\"LinkNotFoundError\")\n",
    "        \n",
    "    app = xw.App()\n",
    "    filebook = xw.Book(link)\n",
    "    \n",
    "    data = filebook.sheets[sheet].range(excel_range).value\n",
    "    \n",
    "    filebook.close()\n",
    "    app.quit()\n",
    "    \n",
    "    if return_df:\n",
    "        df = pd.DataFrame(data[1:], columns = data[0]).dropna(how = \"all\", axis = \"rows\").dropna(how = \"all\", axis = \"columns\")\n",
    "        df.columns = map(str.upper, df.columns)\n",
    "\n",
    "    else:\n",
    "        df = data\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Password for this exercise file is \"pswd\" no quotation marks (applies to all password-protected files).  \n",
    "\n",
    "When using this function, few things to take note:\n",
    "- If range is unknown, you can specify a large range (aka A1:PZ30000) that will definitely be larger than your data ranges. Naturally, the computational time to read in the data will be proportionately longer.\n",
    "- It is assumed that the first row to be read (A1:PZ1) will be the column names. I have also converted them to uppercase to ensure consistency.\n",
    "- Opening (and reading) the file (especially sharepoint) will take some time as the excel client needs to be booted from the backend.\n",
    "- This package (xlwings) will read excel data as list of lists. For example, there are 2 rows within this list:  \n",
    "    *[[Name, Age, Score], [John, 27, 56.9]]*\n",
    "    - Hence, columns are specified above as data[0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pswd_file = os.path.join(path_to_file, \"data_pswd.xlsx\").replace(\"\\\\\", \"/\")\n",
    "df_pswd = read_pswd_excel(link = pswd_file, sheet = \"Sheet1\", excel_range = \"A1:BZ10000\")\n",
    "list_pswd = read_pswd_excel(link = pswd_file, sheet = \"Sheet1\", excel_range = \"A1:BZ10000\", return_df = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>27.0</td>\n",
       "      <td>56.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy</td>\n",
       "      <td>30.0</td>\n",
       "      <td>45.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alfred</td>\n",
       "      <td>24.0</td>\n",
       "      <td>63.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benjamin</td>\n",
       "      <td>35.0</td>\n",
       "      <td>85.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       NAME   AGE  SCORE\n",
       "0      John  27.0   56.9\n",
       "1       Amy  30.0   45.7\n",
       "2    Alfred  24.0   63.4\n",
       "3  Benjamin  35.0   85.3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that the age columns are converted into float. This requires cleaning.\n",
    "df_pswd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of list = 10000\n",
      "Name\n",
      "Age\n",
      "Score\n",
      "John\n",
      "27.0\n",
      "56.9\n",
      "Amy\n",
      "30.0\n",
      "45.7\n",
      "Alfred\n",
      "24.0\n",
      "63.4\n",
      "Benjamin\n",
      "35.0\n",
      "85.3\n"
     ]
    }
   ],
   "source": [
    "# For list_pswd, as we read in a super long range (A1:BZ10000), it may take time to read all the list.\n",
    "# It is not recommended to read it via list of lists, as it will take longer to do data cleaning.\n",
    "print(\"Length of list = {}\".format(len(list_pswd)))\n",
    "for a in range(5):\n",
    "    for b in range(3):\n",
    "        print(list_pswd[a][b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\intranet.dos.gov.sg\\DavWWWRoot\\sites\\ead2\\Common\\NAC\\Workgroup\\PST\\Reference Materials\\Usable Codes\\Python\\File IO\\main\n"
     ]
    }
   ],
   "source": [
    "# Proof of concept using sharepoint file\n",
    "# Should be Python\\File IO, not Python\\File IO\\main\n",
    "print(shareptdir)\n",
    "\n",
    "# Only run this if the last slash ends with main\n",
    "#shareptdir = os.path.dirname(shareptdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharept_file = os.path.join(shareptdir, \"data_pswd.xlsx\").replace(\"\\\\\", \"/\")\n",
    "df_sharept = read_pswd_excel(link = sharept_file, sheet = \"Sheet1\", excel_range = \"A1:D10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>27.0</td>\n",
       "      <td>56.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy</td>\n",
       "      <td>30.0</td>\n",
       "      <td>45.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alfred</td>\n",
       "      <td>24.0</td>\n",
       "      <td>63.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benjamin</td>\n",
       "      <td>35.0</td>\n",
       "      <td>85.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       NAME   AGE  SCORE\n",
       "0      John  27.0   56.9\n",
       "1       Amy  30.0   45.7\n",
       "2    Alfred  24.0   63.4\n",
       "3  Benjamin  35.0   85.3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sharept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__If you have multiple sheets to read from a single file, consider this modified snippet of code__  \n",
    "\n",
    "(not run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires xlwings, as well as os and pandas\n",
    "import os\n",
    "import pandas as pd\n",
    "import xlwings as xw\n",
    "\n",
    "# example only. I have not created such a file.\n",
    "# Both lengths should be same as you need the sheet name to read the ranges within.\n",
    "sheets = [\"Sheet1\", \"Sheet2\", \"Sheet3\"]\n",
    "excel_rng = [\"A1:B30\", \"B2:DZ2000\", \"A1:G2\"]\n",
    "link = \"path_to_file_with_many_sheets\"\n",
    "\n",
    "output_dict = {}\n",
    "\n",
    "app = xw.App()\n",
    "filebook = xw.Book(link)\n",
    "\n",
    "# Read however many sheets from each file.\n",
    "# For repetitive tasks like this, best to read into a dict\n",
    "\n",
    "for i in range(len(sheets)):\n",
    "    data = filebook.sheets[sheets[i]].range(excel_rng[i]).value\n",
    "    df = pd.DataFrame(data[1:], columns = data[0]).dropna(how = \"all\", axis = \"rows\").dropna(how = \"all\", axis = \"columns\")\n",
    "    df.columns = map(str.upper, df.columns)\n",
    "    \n",
    "    output_dict[sheets[i]] = df \n",
    "\n",
    "filebook.close()\n",
    "app.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Please edit the function to suit your data needs. I think that the above code covers most if not all of the use cases currently for my work.__  \n",
    "\n",
    "#### Part 1bii: Creating password automatically for excel files  \n",
    "\n",
    "This last section of part 1b will show you how to create passwords for your excel files on Desktop as well as on sharepoint. This function can be appended at the end of helper.py. You can then import it into the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages\n",
    "import win32com.client as win32\n",
    "import os\n",
    "#from pathlib import Path\n",
    "\n",
    "def encrypt_file(full_filename, pswd = \"pswd\", intranet = \"no\", replace = \"no\"):\n",
    "\n",
    "    '''\n",
    "    Function only supports \\ slashes.\n",
    "    First it checks if the path exists or not. Ensure that you are connected to sharepoint.\n",
    "    If the slashes are wrong, the function will try to change them.\n",
    "    For intranet files, we will append a \"1\" to the filename so we can save as a different file.\n",
    "    If replace is set to yes, we will delete the original file, and rename the new file -> original file\n",
    "    '''        \n",
    "    \n",
    "    if not os.path.exists(full_filename):\n",
    "        print(\"Filename does not exist.\")\n",
    "        \n",
    "    if \"\\\\\" not in full_filename:\n",
    "        print(\"Password encryption does not support </> slashes but only <\\> slashes. Changing it now\")\n",
    "    \n",
    "    full_filename = full_filename.replace(\"/\", \"\\\\\")\n",
    "    print(\"If there is a prompt asking if you want to overwrite the file. Put yes.\")\n",
    "    \n",
    "    excel = win32.gencache.EnsureDispatch(\"Excel.Application\")\n",
    "    excel.DisplayAlerts = False\n",
    "    wb = excel.Workbooks.Open(full_filename)\n",
    "    \n",
    "    # If intranet, try another method\n",
    "    if \"intranet.dos.gov.sg\" in full_filename or intranet.lower() == \"yes\":\n",
    "        print(\"Intranet file. To save as another file. Please delete as needed.\")\n",
    "        new_fullfilename = full_filename.replace(\".xlsx\", \"1.xlsx\")\n",
    "        wb.SaveAs(new_fullfilename, 51, pswd)\n",
    "        \n",
    "    else:\n",
    "        print(\"Local file. To overwrite.\")\n",
    "        wb.SaveAs(full_filename, 51, pswd)\n",
    "    \n",
    "    wb.Close()\n",
    "    excel.Application.Quit()\n",
    "        \n",
    "    # Buggy - do not use.\n",
    "    #if replace.lower() == \"yes\":\n",
    "        #print(\"Replacing file...\")\n",
    "        #os.remove(full_filename)\n",
    "        #os.rename(new_fullfilename, full_filename)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kbkoh\\Desktop\\PST\\helper\\files\\read\\data_to_encrypt.xlsx\n"
     ]
    }
   ],
   "source": [
    "file_to_encrypt = os.path.join(path_to_file, \"data_to_encrypt.xlsx\").replace(\"/\", \"\\\\\")\n",
    "\n",
    "print(file_to_encrypt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If there is a prompt asking if you want to overwrite the file. Put yes.\n",
      "Local file. To overwrite.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encrypt_file(file_to_encrypt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to test if it works\n",
    "df_encrypt = read_pswd_excel(file_to_encrypt, sheet = \"Sheet1\", excel_range = \"A1:D5\")\n",
    "df_encrypt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have tested it on SharePoint and that it works. Only run this once. This can be done with a loop to handle multiple files as well. The idea is for you to take the essence of this code and tweak it to your section's requirements and file location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\intranet.dos.gov.sg\\DavWWWRoot\\sites\\ead2\\Common\\NAC\\Workgroup\\PST\\Reference Materials\\Usable Codes\\Python\\File IO\\data_to_encrypt.xlsx\n",
      "If there is a prompt asking if you want to overwrite the file. Put yes.\n",
      "Intranet file. To save as another file. Please delete as needed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file to encrypt exists one level up so that user does not confuse it with the file in main folder (meant for testing of automatic encryption in local drive).\n",
    "\n",
    "shareptfile_to_encrypt = os.path.join(r\"\\\\intranet.dos.gov.sg\\DavWWWRoot\\sites\\ead2\\Common\\NAC\\Workgroup\\PST\\Reference Materials\\Usable Codes\\Python\\File IO\", \"data_to_encrypt.xlsx\").replace(\"/\", \"\\\\\")\n",
    "print(shareptfile_to_encrypt)\n",
    "#shareptdir = r\"\\\\intranet.dos.gov.sg\\DavWWWRoot\\sites\\ead2\\Common\\NAC\\Workgroup\\PST\\Reference Materials\\Usable Codes\\Python\\File IO\\main\"\n",
    "\n",
    "encrypt_file(shareptfile_to_encrypt, intranet = \"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>27.0</td>\n",
       "      <td>56.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy</td>\n",
       "      <td>30.0</td>\n",
       "      <td>45.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alfred</td>\n",
       "      <td>24.0</td>\n",
       "      <td>63.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benjamin</td>\n",
       "      <td>35.0</td>\n",
       "      <td>85.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       NAME   AGE  SCORE\n",
       "0      John  27.0   56.9\n",
       "1       Amy  30.0   45.7\n",
       "2    Alfred  24.0   63.4\n",
       "3  Benjamin  35.0   85.3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to test if it works\n",
    "shareptfile_to_encrypt_1 = shareptfile_to_encrypt[:-5] + \"1.xlsx\"\n",
    "\n",
    "df_encrypt = read_pswd_excel(shareptfile_to_encrypt_1, sheet = \"Sheet1\", excel_range = \"A1:D5\")\n",
    "df_encrypt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id = \"VOL1_dat\">Part 1c: .dat or .txt files  </a>  \n",
    "\n",
    "[Return to Table of Contents](#VOL1_toc)\n",
    "\n",
    ".dat files usually contain important information for software to handle. The information is usually in plain text or binary. By right, they should be used by the applications themselves. As you may be uncertain about the structure within, you can take a look inside by opening the file with Notepad. Note that you can also read text files via the methods below.  \n",
    "\n",
    "Here is an example I made based off of the same data above:\n",
    "\n",
    "Edit: The current version of Jupyter Notebook cannot insert images (2015 version still). You can manually open *files/data_dat.txt* with a notepad or *./data_dat.PNG*.  \n",
    "\n",
    "The way to read the dat file is to understand if its a fixed width or a delimiter (comma, tab, newline etc) that separates the values. If commas, can treat it as csv. If tab, can read it line by line.  \n",
    "\n",
    "#### CSV package:  \n",
    "\n",
    "The CSV package is a general purpose package to read files that are delimited by something. Can be tabs, newline, space, comma, or any other character, even \"a\". This should come pre-installed with Python. There is no need to install a new package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Name', 'Age', 'Score']\n",
      "['John', '27', '56.9']\n",
      "['Amy', '30', '45.7']\n",
      "['Alfred', '24', '63.4']\n",
      "['Benjamin', '35', '85.3']\n"
     ]
    }
   ],
   "source": [
    "import csv # A package that helps.\n",
    "\n",
    "mylist = []\n",
    "# relative path is used. You can also use the absolute path via dirname and os.path.join\n",
    "with open(\"files/read/data.txt\", \"r\") as file:\n",
    "    alist = csv.reader(file, delimiter = \"\\t\")\n",
    "    for line in alist:\n",
    "        print(line)\n",
    "        mylist.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ï»¿Name', 'Age', 'Score']\n",
      "['John', '27', '56.9']\n",
      "['Amy', '30', '45.7']\n",
      "['Alfred', '24', '63.4']\n",
      "['Benjamin', '35', '85.3']\n"
     ]
    }
   ],
   "source": [
    "with open(\"files/read/data.csv\", \"r\") as file:\n",
    "    alist = csv.reader(file, delimiter = \",\")\n",
    "    for line in alist:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see any difference with the example above that highlighted encoding encoding?  \n",
    "\n",
    "[Part 1a here](#VOL1_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_txt = pd.DataFrame(mylist[1:], columns = mylist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>27</td>\n",
       "      <td>56.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy</td>\n",
       "      <td>30</td>\n",
       "      <td>45.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alfred</td>\n",
       "      <td>24</td>\n",
       "      <td>63.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benjamin</td>\n",
       "      <td>35</td>\n",
       "      <td>85.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name Age Score\n",
       "0      John  27  56.9\n",
       "1       Amy  30  45.7\n",
       "2    Alfred  24  63.4\n",
       "3  Benjamin  35  85.3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name          Age         Score\\n',\n",
       " 'John          27          56.9\\n',\n",
       " 'Amy           30          45.7\\n',\n",
       " 'Alfred        24          63.4\\n',\n",
       " 'Benjamin      35          85.3']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"files/read/data.dat\", \"r\") as file:\n",
    "    dat_list = file.readlines()\n",
    "\n",
    "# To understand what the data looks like. \n",
    "# The output below will take quite some lines of code to clean. We can try fixed width formatting.\n",
    "# Thanks Wei Liang from IA for sharing the code (.read_fwf) with me.\n",
    "dat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voila! Pandas automatically infers the fixed width needed to split the values.\n",
    "# However, without looking at the files itself, we won't know if its fixed width or not.\n",
    "dat_df = pd.read_fwf(\"files/read/data.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>27</td>\n",
       "      <td>56.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy</td>\n",
       "      <td>30</td>\n",
       "      <td>45.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alfred</td>\n",
       "      <td>24</td>\n",
       "      <td>63.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benjamin</td>\n",
       "      <td>35</td>\n",
       "      <td>85.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  Age  Score\n",
       "0      John   27   56.9\n",
       "1       Amy   30   45.7\n",
       "2    Alfred   24   63.4\n",
       "3  Benjamin   35   85.3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id = \"VOL1_sas\">Part 1d: .sas7bdat files  </a>  \n",
    "\n",
    "[Return to Table of Contents](#VOL1_toc)  \n",
    "\n",
    "SAS dataset files can be read by pandas, with one caveat: Encrypted files cannot be opened by pandas. Pandas only works on unencrypted SAS datasets, with the extension SAS7bdat. As the SAS ecosystem isn't really designed from an open-sourced kind of perspective, it can be difficult to interact with files directly. For most SAS data, you can use their export task to export either as an excel file or even as a text file, which you can then read via pandas' functions as above.  \n",
    "\n",
    "Hence, using a SAS7bdat file in anywhere else other than SAS is not recommended. Below shows an example (not run) of how you would write code to read SAS files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_sas in module pandas.io.sas.sasreader:\n",
      "\n",
      "read_sas(filepath_or_buffer, format=None, index=None, encoding=None, chunksize=None, iterator=False)\n",
      "    Read SAS files stored as either XPORT or SAS7BDAT format files.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    filepath_or_buffer : string or file-like object\n",
      "        Path to the SAS file.\n",
      "    format : string {'xport', 'sas7bdat'} or None\n",
      "        If None, file format is inferred from file extension. If 'xport' or\n",
      "        'sas7bdat', uses the corresponding format.\n",
      "    index : identifier of index column, defaults to None\n",
      "        Identifier of column that should be used as index of the DataFrame.\n",
      "    encoding : string, default is None\n",
      "        Encoding for text data.  If None, text data are stored as raw bytes.\n",
      "    chunksize : int\n",
      "        Read file `chunksize` lines at a time, returns iterator.\n",
      "    iterator : bool, defaults to False\n",
      "        If True, returns an iterator for reading the file incrementally.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame if iterator=False and chunksize=None, else SAS7BDATReader\n",
      "    or XportReader\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# help is a great function so you can check the parameters that are required to use this function.\n",
    "help(pd.read_sas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sas(\"path_to_sas_file.sas7bdat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id = \"VOL1_json\">Part 1e: JSON files</a>  \n",
    "\n",
    "[Return to Table of Contents](#VOL1_toc)  \n",
    "\n",
    "The last part of this guide on File I/O will focus on json files. JSON = JavaScript Object Notation, which is the data-exchange format that is lightweight, require less coding, processes faster and human-readable. Most data dumps from online sources (esp from Kaggle) are in either JSON or XML files.  \n",
    "\n",
    "*** Note that json file can't seem to be uploaded onto SharePoint. In the example below, I will create the json file myself so you can read from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_json = pd.DataFrame({\"Name\":\n",
    " {\"0\":\"John\",\"1\":\"Amy\",\"2\":\"Alfred\",\"3\":\"Benjamin\"},\n",
    " \"Age\":{\"0\":27,\"1\":30,\"2\":24,\"3\":35},\n",
    " \"Score\":{\"0\":56.9,\"1\":45.7,\"2\":63.4,\"3\":85.3}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_json.to_json(\"files/read/data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>27</td>\n",
       "      <td>56.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy</td>\n",
       "      <td>30</td>\n",
       "      <td>45.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alfred</td>\n",
       "      <td>24</td>\n",
       "      <td>63.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benjamin</td>\n",
       "      <td>35</td>\n",
       "      <td>85.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  Age  Score\n",
       "0      John   27   56.9\n",
       "1       Amy   30   45.7\n",
       "2    Alfred   24   63.4\n",
       "3  Benjamin   35   85.3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"files/read/data.json\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that while it seems incredibly easy to read json files, you would need to note that they follow certain rules. If your json dataset is structured differently, you would need to do some data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': {'0': 'John', '1': 'Amy', '2': 'Alfred', '3': 'Benjamin'},\n",
       " 'Age': {'0': 27, '1': 30, '2': 24, '3': 35},\n",
       " 'Score': {'0': 56.9, '1': 45.7, '2': 63.4, '3': 85.3}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"files/read/data.json\") as file:   \n",
    "    data = json.load(file)\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column is Name\n",
      "Row index = 0, row value = John\n",
      "Row index = 1, row value = Amy\n",
      "Row index = 2, row value = Alfred\n",
      "Row index = 3, row value = Benjamin\n",
      "Column is Age\n",
      "Row index = 0, row value = 27\n",
      "Row index = 1, row value = 30\n",
      "Row index = 2, row value = 24\n",
      "Row index = 3, row value = 35\n",
      "Column is Score\n",
      "Row index = 0, row value = 56.9\n",
      "Row index = 1, row value = 45.7\n",
      "Row index = 2, row value = 63.4\n",
      "Row index = 3, row value = 85.3\n"
     ]
    }
   ],
   "source": [
    "for cols in data.keys():\n",
    "    print(\"Column is {}\".format(cols))\n",
    "    for index, rows in data[cols].items():\n",
    "        print(\"Row index = {}, row value = {}\".format(index, rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a rule of thumb, generally speaking it is best to read a json file via notepad to assess its contents first, or read in the json file via json.load() to understand the data before converting it to pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id = \"VOL1_write_excel\"> Part 2: Writing files  </a>\n",
    "[Return to Table of Contents](#VOL1_toc) \n",
    "\n",
    "2A: [Writing to password-protected Excel Files](#VOL1_writepswdexcel)  \n",
    "2B: [Writing to other file types](#VOL1_writeothfile)  \n",
    "\n",
    "This section will touch on how to write to files and the *cheat* codes that I (and many other users) are using that can help save valuable amounts of coding time. This can be run independently of Part 1.\n",
    "\n",
    "Writing data to files are simple. A few ways you can do it; mostly via Excel as the format is most commonly used. The pandas package can do most data writing requirements. For specific excel manipulation (e.g. writing to cell A10 or deleting rows etc), best to use excel-specific packages such as openpyxl or xlwings.\n",
    "\n",
    "To ensure that each step can be executed independently, we can read from existing files and write it into our new file which will exist in the Write folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get directory name of this file. Helpful to specify the directory of the file, \n",
    "# so you can also interact with the files in the same location via relative paths.\n",
    "\n",
    "dirname = globals()[\"_dh\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylines = [\"KKB\", \"100\", 99.9]\n",
    "\n",
    "rawfile = os.path.join(dirname, \"files\", \"read\", \"data.xlsx\").replace(\"\\\\\", \"/\")\n",
    "\n",
    "# Read from old file any file will do as the data is the same\n",
    "rawdata = pd.read_excel(rawfile, sheet_name = \"Sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>27</td>\n",
       "      <td>56.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy</td>\n",
       "      <td>30</td>\n",
       "      <td>45.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alfred</td>\n",
       "      <td>24</td>\n",
       "      <td>63.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benjamin</td>\n",
       "      <td>35</td>\n",
       "      <td>85.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  Age  Score\n",
       "0      John   27   56.9\n",
       "1       Amy   30   45.7\n",
       "2    Alfred   24   63.4\n",
       "3  Benjamin   35   85.3"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append list regardless of position. Assume you've ordered it correctly.\n",
    "rawdata.loc[4] = mylines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>27</td>\n",
       "      <td>56.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy</td>\n",
       "      <td>30</td>\n",
       "      <td>45.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alfred</td>\n",
       "      <td>24</td>\n",
       "      <td>63.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benjamin</td>\n",
       "      <td>35</td>\n",
       "      <td>85.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KKB</td>\n",
       "      <td>100</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  Age  Score\n",
       "0      John   27   56.9\n",
       "1       Amy   30   45.7\n",
       "2    Alfred   24   63.4\n",
       "3  Benjamin   35   85.3\n",
       "4       KKB  100   99.9"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing it back to the excel file can take many forms.  \n",
    "\n",
    "- Writing to sheets\n",
    "- Writing to specific cells  \n",
    "- Writing to new file\n",
    "\n",
    "Note that you cannot write into the file if you have the file open. That implies an open 'connection' between the file and your Operating System. As such, you need to close it before you can write to the file (connection between file and python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do you think that there will be 1 tab or 2 tabs in the new_excel after this cell is run?\n",
    "rawdata.to_excel(\"files/write/new_excel.xlsx\", index = False)\n",
    "rawdata.to_excel(\"files/write/new_excel.xlsx\", index = False, sheet_name = \"testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write multiple sheets at the same time into an excel file, you can take a look at the syntax (see help(code) below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(\"files/write/new_excel_2.xlsx\") as writer:  # doctest: +SKIP\n",
    "        rawdata.to_excel(writer, sheet_name=\"Sheet1\")\n",
    "        rawdata.to_excel(writer, sheet_name=\"Sheet2\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For me, I use the below as a template to save a backup, remove sheets that we want to replace/add (if you don't the sheet name \"Sheet1\" will be changed to \"Sheet11\" because you can't have 2 sheets with the same name), and write the DataFrame as a new sheet. After that, you save it and the file will be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/kbkoh/Desktop/PST/helper/files/write/new_excel_3.xlsx\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Backup and save the file (while retaining the sheets.)\n",
    "\n",
    "output_file = os.path.join(dirname, \"files/write/new_excel_3.xlsx\").replace(\"\\\\\", \"/\")\n",
    "output_file_bkup = os.path.join(dirname, \"files/write/new_excel_3_bkup.xlsx\").replace(\"\\\\\", \"/\")\n",
    "shutil.copy(output_file, output_file_bkup)\n",
    "print(output_file)\n",
    "\n",
    "book = load_workbook(output_file)\n",
    "writer = pd.ExcelWriter(output_file, engine = \"openpyxl\")\n",
    "writer.book = book\n",
    "\n",
    "# Sheet to remove\n",
    "# Then insert the new sheet. This is cleaner.\n",
    "for i in [\"Sheet1\", \"Sheet2\"]:\n",
    "    if i in writer.book:\n",
    "        writer.book.remove(book[i])\n",
    "\n",
    "rawdata.to_excel(writer, index = False, sheet_name = \"Sheet1\")\n",
    "rawdata.to_excel(writer, sheet_name = \"Sheet2\")\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if the excel file is encrypted, you will need a different package to write to it. For the above code, after the file is refreshed with the new data, if you wish to encrypt the file, you can run the encrypt_file() function (you need to run it once to define the function for use).  \n",
    "\n",
    "#### <a id = \"VOL1_writepswdexcel\"> Part 2A: Writing to password-protected excel files  </a>\n",
    "\n",
    "[Return to top](#VOL1_toc)  \n",
    "[Return to section head](#VOL1_write_excel)\n",
    "\n",
    "This will demonstrate how to write the same dataframe as above into a password protected excel file. The interface can also work on non-password protected excel file. The codes are similar to that used to open password-protected excel files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwings\n",
    "output_file = os.path.join(dirname, \"files/write/new_excel_4.xlsx\").replace(\"\\\\\", \"/\")\n",
    "\n",
    "app = xw.App()\n",
    "filebook = xw.Book(output_file)\n",
    "\n",
    "# Add sheet\n",
    "filebook.sheets.add(name = \"newsheet1\")\n",
    "filebook.sheets[\"newsheet1\"].range(\"A1\").options(index = False).value = rawdata\n",
    "\n",
    "filebook.sheets.add(name = \"newsheet2\")\n",
    "filebook.sheets[\"newsheet2\"].range(\"B2\").value = rawdata\n",
    "\n",
    "# Add data to existing sheet\n",
    "filebook.sheets[\"DO NOT DELETE\"].range(\"F1\").value = rawdata\n",
    "\n",
    "newfile = os.path.join(dirname, \"files/write/new_excel_4a.xlsx\").replace(\"\\\\\", \"/\")\n",
    "\n",
    "# unlike reading, we need to save the file.\n",
    "# If .save() is empty, it will simply overwrite the file. I will save as a new file so that the results can be reproduced.\n",
    "filebook.save(newfile)\n",
    "app.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read the excel file to see the sheet first so you can compare the files.\n",
    "\n",
    "Note that while you can write to an existing sheet, you can also do many things with the excel file. This includes, changing the color, formatting, clearning the contents of the sheet, as well as deleting it. Please take a look at their documentation.  \n",
    "\n",
    "Another example below. Take note of the difference in syntax when checking for name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = os.path.join(dirname, \"files/write/new_excel_4a.xlsx\").replace(\"\\\\\", \"/\")\n",
    "\n",
    "app = xw.App()\n",
    "filebook = xw.Book(output_file)\n",
    "\n",
    "for sheet in filebook.sheets:\n",
    "    if \"newsheet1\" in sheet.name:\n",
    "        filebook.sheets[\"newsheet1\"].clear()\n",
    "        filebook.sheets[\"newsheet1\"].range(\"A10\").options(index = False).value = rawdata\n",
    "        # This can also be a single cell, or a range. This is what online says to be the most efficient method.\n",
    "        # Take a look at chunksize if you're looking to write a huge dataset. For that, I usually recommend writing to a excel file, \n",
    "        # THEN encrypting it so that its simpler to do.\n",
    "        \n",
    "    if \"newsheet2\" in sheet.name:\n",
    "        filebook.sheets[\"newsheet2\"].delete()\n",
    "        \n",
    "newfile = os.path.join(dirname, \"files/write/new_excel_4b.xlsx\").replace(\"\\\\\", \"/\")\n",
    "\n",
    "filebook.save(newfile)\n",
    "app.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id = \"VOL1_writeothfile\"> Part 2B: Writing to other file types </a>\n",
    "[Return to top](#VOL1_toc)  \n",
    "[Return to section head](#VOL1_write_excel)\n",
    "\n",
    "This will demonstrate how to write the same dataframe into other file types as may be required. This won't be common as the file formats are usually excel, csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Get directory name of this file. Helpful to specify the directory of the file, \n",
    "# so you can also interact with the files in the same location via relative paths.\n",
    "\n",
    "dirname = globals()[\"_dh\"][0]\n",
    "mylines = [\"KKB\", \"100\", 99.9]\n",
    "\n",
    "rawfile = os.path.join(dirname, \"files\", \"read\", \"data.xlsx\").replace(\"\\\\\", \"/\")\n",
    "\n",
    "# Read from old file any file will do as the data is the same\n",
    "rawdata = pd.read_excel(rawfile, sheet_name = \"Sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append list regardless of position. Assume you've ordered it correctly.\n",
    "rawdata.loc[4] = mylines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>27</td>\n",
       "      <td>56.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy</td>\n",
       "      <td>30</td>\n",
       "      <td>45.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alfred</td>\n",
       "      <td>24</td>\n",
       "      <td>63.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benjamin</td>\n",
       "      <td>35</td>\n",
       "      <td>85.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KKB</td>\n",
       "      <td>100</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  Age  Score\n",
       "0      John   27   56.9\n",
       "1       Amy   30   45.7\n",
       "2    Alfred   24   63.4\n",
       "3  Benjamin   35   85.3\n",
       "4       KKB  100   99.9"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "to_sql() missing 2 required positional arguments: 'name' and 'con'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-92167c8bda27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Error will occur by design.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mrawdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: to_sql() missing 2 required positional arguments: 'name' and 'con'"
     ]
    }
   ],
   "source": [
    "rawdata.to_csv(\"files/write/newdata.csv\")\n",
    "\n",
    "# Error will occur by design, as we've not specified the sql database.\n",
    "rawdata.to_sql()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple troubleshooting process is to refer to their documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method to_sql in module pandas.core.generic:\n",
      "\n",
      "to_sql(name, con, schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None, method=None) method of pandas.core.frame.DataFrame instance\n",
      "    Write records stored in a DataFrame to a SQL database.\n",
      "    \n",
      "    Databases supported by SQLAlchemy [1]_ are supported. Tables can be\n",
      "    newly created, appended to, or overwritten.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    name : string\n",
      "        Name of SQL table.\n",
      "    con : sqlalchemy.engine.Engine or sqlite3.Connection\n",
      "        Using SQLAlchemy makes it possible to use any DB supported by that\n",
      "        library. Legacy support is provided for sqlite3.Connection objects.\n",
      "    schema : string, optional\n",
      "        Specify the schema (if database flavor supports this). If None, use\n",
      "        default schema.\n",
      "    if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      "        How to behave if the table already exists.\n",
      "    \n",
      "        * fail: Raise a ValueError.\n",
      "        * replace: Drop the table before inserting new values.\n",
      "        * append: Insert new values to the existing table.\n",
      "    \n",
      "    index : bool, default True\n",
      "        Write DataFrame index as a column. Uses `index_label` as the column\n",
      "        name in the table.\n",
      "    index_label : string or sequence, default None\n",
      "        Column label for index column(s). If None is given (default) and\n",
      "        `index` is True, then the index names are used.\n",
      "        A sequence should be given if the DataFrame uses MultiIndex.\n",
      "    chunksize : int, optional\n",
      "        Rows will be written in batches of this size at a time. By default,\n",
      "        all rows will be written at once.\n",
      "    dtype : dict, optional\n",
      "        Specifying the datatype for columns. The keys should be the column\n",
      "        names and the values should be the SQLAlchemy types or strings for\n",
      "        the sqlite3 legacy mode.\n",
      "    method : {None, 'multi', callable}, default None\n",
      "        Controls the SQL insertion clause used:\n",
      "    \n",
      "        * None : Uses standard SQL ``INSERT`` clause (one per row).\n",
      "        * 'multi': Pass multiple values in a single ``INSERT`` clause.\n",
      "        * callable with signature ``(pd_table, conn, keys, data_iter)``.\n",
      "    \n",
      "        Details and a sample callable implementation can be found in the\n",
      "        section :ref:`insert method <io.sql.method>`.\n",
      "    \n",
      "        .. versionadded:: 0.24.0\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        When the table already exists and `if_exists` is 'fail' (the\n",
      "        default).\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    read_sql : Read a DataFrame from a table.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Timezone aware datetime columns will be written as\n",
      "    ``Timestamp with timezone`` type with SQLAlchemy if supported by the\n",
      "    database. Otherwise, the datetimes will be stored as timezone unaware\n",
      "    timestamps local to the original timezone.\n",
      "    \n",
      "    .. versionadded:: 0.24.0\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] http://docs.sqlalchemy.org\n",
      "    .. [2] https://www.python.org/dev/peps/pep-0249/\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    \n",
      "    Create an in-memory SQLite database.\n",
      "    \n",
      "    >>> from sqlalchemy import create_engine\n",
      "    >>> engine = create_engine('sqlite://', echo=False)\n",
      "    \n",
      "    Create a table from scratch with 3 rows.\n",
      "    \n",
      "    >>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})\n",
      "    >>> df\n",
      "         name\n",
      "    0  User 1\n",
      "    1  User 2\n",
      "    2  User 3\n",
      "    \n",
      "    >>> df.to_sql('users', con=engine)\n",
      "    >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      "    [(0, 'User 1'), (1, 'User 2'), (2, 'User 3')]\n",
      "    \n",
      "    >>> df1 = pd.DataFrame({'name' : ['User 4', 'User 5']})\n",
      "    >>> df1.to_sql('users', con=engine, if_exists='append')\n",
      "    >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      "    [(0, 'User 1'), (1, 'User 2'), (2, 'User 3'),\n",
      "     (0, 'User 4'), (1, 'User 5')]\n",
      "    \n",
      "    Overwrite the table with just ``df1``.\n",
      "    \n",
      "    >>> df1.to_sql('users', con=engine, if_exists='replace',\n",
      "    ...            index_label='id')\n",
      "    >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      "    [(0, 'User 4'), (1, 'User 5')]\n",
      "    \n",
      "    Specify the dtype (especially useful for integers with missing values).\n",
      "    Notice that while pandas is forced to store the data as floating point,\n",
      "    the database supports nullable integers. When fetching the data with\n",
      "    Python, we get back integer scalars.\n",
      "    \n",
      "    >>> df = pd.DataFrame({\"A\": [1, None, 2]})\n",
      "    >>> df\n",
      "         A\n",
      "    0  1.0\n",
      "    1  NaN\n",
      "    2  2.0\n",
      "    \n",
      "    >>> from sqlalchemy.types import Integer\n",
      "    >>> df.to_sql('integers', con=engine, index=False,\n",
      "    ...           dtype={\"A\": Integer()})\n",
      "    \n",
      "    >>> engine.execute(\"SELECT * FROM integers\").fetchall()\n",
      "    [(1,), (None,), (2,)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(rawdata.to_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full list of methods, from dir(pd.DataFrame)\n",
    "'to_clipboard',\n",
    " 'to_csv',\n",
    " 'to_dense',\n",
    " 'to_dict',\n",
    " 'to_excel',\n",
    " 'to_feather',\n",
    " 'to_gbq',\n",
    " 'to_hdf',\n",
    " 'to_html',\n",
    " 'to_json',\n",
    " 'to_latex',\n",
    " 'to_msgpack',\n",
    " 'to_numpy',\n",
    " 'to_panel',\n",
    " 'to_parquet',\n",
    " 'to_period',\n",
    " 'to_pickle',\n",
    " 'to_records',\n",
    " 'to_sparse',\n",
    " 'to_sql',\n",
    " 'to_stata',\n",
    " 'to_string',\n",
    " 'to_timestamp',\n",
    " 'to_xarray',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thank you for reading thus far. Hope you learnt something new in this guide. Onto VOL2: Data processing, or VOL3: Exploratory Data Analysis!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
